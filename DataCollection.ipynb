{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95c6193e",
   "metadata": {},
   "source": [
    "# Tax Appeal\n",
    "### Created by: Ryan Jinnette\n",
    "\n",
    "#### This file uses selenium and pandas to scrape county website for tax records that will be used for analysis to fair price valuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4afcfc3",
   "metadata": {},
   "source": [
    "## Set Up and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c06af8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install selenium\n",
    "# !pip install pandas\n",
    "# !pip install rpy2\n",
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b9face3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "import chromedriver_autoinstaller\n",
    "import time\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from tqdm import tqdm\n",
    "import rpy2\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "#import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83891cda",
   "metadata": {},
   "source": [
    "## Constants and Class Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3a37ea15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class lot:\n",
    "    '''This class provides a framework to store data more easily instead of multiple lists.\n",
    "    I can reference just the instance of the class'''\n",
    "    def __init__(self, prop_id=None, geo_id=None, name=None, appraised=None, land_value=None, land_size=None, improved_value=None, sqft=None, year=None, bldg_class=None):\n",
    "        self.prop_id = prop_id\n",
    "        self.geo_id = geo_id\n",
    "        self.name = name\n",
    "        self.appraised = appraised\n",
    "        self.land_value = land_value\n",
    "        self.land_size = land_size\n",
    "        self.improved_value = improved_value\n",
    "        self.imp_sqft = sqft\n",
    "        self.year = year\n",
    "        self.bldg_class = bldg_class\n",
    "        self.dollar_sqft = None\n",
    "    \n",
    "    def set_dtypes(self):\n",
    "        '''used to keep things consistent so that math can be done on all cells and not throw errors'''\n",
    "        self.improved_value = float(self.improved_value.replace('(+)','').replace(',','').replace('$',''))\n",
    "        self.appraised = float(self.appraised.replace(',','').replace('$',''))\n",
    "        self.land_value = float(self.land_value.replace(',','').replace('$',''))\n",
    "        self.land_size = float(self.land_size.replace(',',''))\n",
    "        if self.imp_sqft != 0:\n",
    "            self.imp_sqft = float(self.imp_sqft[13:-4].strip().replace(',',''))\n",
    "            #self.dollar_sqft = round(self.improved_value / self.imp_sqft,2)\n",
    "        \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8ad976bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What year of records would you like to grab? 2023\n"
     ]
    }
   ],
   "source": [
    "lots = []\n",
    "web_url = r'https://esearch.galvestoncad.org/Search/Result?keywords=Johnson%20Crawford#'\n",
    "year = int(input('What year of records would you like to grab? '))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18928c1e",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "#### Iterates over the webpage and grabs all necessary data, adds to the class and uses the XPATH of certain items to track them on the page for easy identification and repeatability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d497a02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|█████████████████████████| 60/60 [03:36<00:00,  3.60s/row]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 216.27 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def collect(web_url,year):\n",
    "    #options = webdriver.ChromeOptions()\n",
    "    #options.add_argument('--headless')\n",
    "    #driver = webdriver.Chrome(options = options)\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(web_url)\n",
    "    driver.implicitly_wait(2) # dynamic waiting to see when any certain searched for object becomes available\n",
    "    time.sleep(2)\n",
    "    \n",
    "    #change the list view to 100 instead of default 25\n",
    "    #btn = driver.find_element(By.ID, 'btnFilterByPage')\n",
    "    #btn.click()\n",
    "    year_script = f\"filterByYear({year});\"\n",
    "    driver.execute_script(year_script)\n",
    "    \n",
    "    page_count_script = \"handlePageSizeChange(100);\"\n",
    "    driver.execute_script(page_count_script)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #btn = driver.find_element(By.XPATH, '/html/body/div[4]/div[3]/div/span[3]/ul/li[3]')\n",
    "    #btn.click()\n",
    "    \n",
    "    time.sleep(2)\n",
    "\n",
    "    rows = driver.find_elements(By.XPATH, '/html/body/div[4]/div[4]/div[2]/table/tbody/tr')\n",
    "    start = time.time()\n",
    "    \n",
    "    for i in tqdm(range(2, len(rows)+1), desc=\"Processing rows\", unit=\"row\"):\n",
    "        # this grabs all initially avail info, will have to go into each property next\n",
    "        prop_id = driver.find_element(By.XPATH, f'/html/body/div[4]/div[4]/div[2]/table/tbody/tr[{i}]/td[1]').text\n",
    "        geo_id = driver.find_element(By.XPATH, f'/html/body/div[4]/div[4]/div[2]/table/tbody/tr[{i}]/td[3]').text\n",
    "        name = driver.find_element(By.XPATH, f'/html/body/div[4]/div[4]/div[2]/table/tbody/tr[{i}]/td[6]').text\n",
    "        appraised = driver.find_element(By.XPATH, f'/html/body/div[4]/div[4]/div[2]/table/tbody/tr[{i}]/td[10]').text\n",
    "        \n",
    "        #go into each property and get more details\n",
    "        click_property = driver.find_element(By.XPATH, f'/html/body/div[4]/div[4]/div[2]/table/tbody/tr[{i}]')\n",
    "        click_property.click()\n",
    "        \n",
    "        land_size = driver.find_element(By.XPATH, f'/html/body/div[4]/div[1]/div[5]/div[2]/table/tbody/tr[2]/td[4]').text\n",
    "        land_value = driver.find_element(By.XPATH, f'/html/body/div[4]/div[1]/div[5]/div[2]/table/tbody/tr[2]/td[7]').text\n",
    "        \n",
    "        # in case any of the following don't exist. (I.E. the lot is land only)\n",
    "        try:\n",
    "            improvement = driver.find_element(By.XPATH, f'/html/body/div[4]/div[1]/div[2]/div[2]/div/table/tbody/tr[3]/td').text\n",
    "        except NoSuchElementException:\n",
    "            improvement = 0\n",
    "        if improvement != '$0 (+)':\n",
    "            try:\n",
    "                imp_sqft = driver.find_element(By.XPATH, f'/html/body/div[4]/div[1]/div[4]/div[2]/div[1]/span[3]').text\n",
    "                if 'State' in imp_sqft: #some of the pages are not consistent formatting, handles that\n",
    "                    imp_sqft = driver.find_element(By.XPATH, f'/html/body/div[4]/div[1]/div[4]/div[2]/div[1]/span[4]').text\n",
    "            except NoSuchElementException:\n",
    "                imp_sqft = 0\n",
    "\n",
    "            try:\n",
    "                year = driver.find_element(By.XPATH,f'/html/body/div[4]/div[1]/div[4]/div[2]/table/tbody/tr[2]/td[5]').text\n",
    "            except NoSuchElementException:\n",
    "                year = 'Nan'\n",
    "\n",
    "            try:\n",
    "                bldg_class = driver.find_element(By.XPATH, f'/html/body/div[4]/div[1]/div[4]/div[2]/table/tbody/tr[2]/td[3]').text\n",
    "            except NoSuchElementException:\n",
    "                bldg_class = 'Nan'\n",
    "        else:\n",
    "            imp_sqft = 0\n",
    "            year = 'Nan'\n",
    "            bldg_class = 'Nan'\n",
    "\n",
    "        \n",
    "        lot_info = lot(prop_id, geo_id, name, appraised, land_value,land_size, improvement, imp_sqft, year, bldg_class)\n",
    "        lots.append(lot_info)\n",
    "        driver.back()\n",
    "    finish = time.time()\n",
    "    print(f\"Took {round(finish-start,2)} seconds\")\n",
    "        \n",
    "collect(web_url,year)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ab323e",
   "metadata": {},
   "source": [
    "### Clean Data and Set Dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "07ba4978",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lot in lots:\n",
    "    lot.set_dtypes()\n",
    "    #print(lot.imp_sqft, type(lot.imp_sqft))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221d1456",
   "metadata": {},
   "source": [
    "### Converting gathered data into csv export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a24542cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_csv():\n",
    "    attribute_names = list(vars(lots[0]).keys())\n",
    "    data = [{attr: getattr(lot, attr) for attr in attribute_names} for lot in lots]\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(f'{year}_data.csv', index = False)\n",
    "\n",
    "convert_to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca28cf79",
   "metadata": {},
   "source": [
    "# Main aggregation of functions in main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ade21115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    collect(web_url,year)\n",
    "    convert_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219b6249",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf2f478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f82e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554de9f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
